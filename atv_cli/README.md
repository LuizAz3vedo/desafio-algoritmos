# AnÃ¡lise de Complexidade de Algoritmos em Python

Este repositÃ³rio contÃ©m 3 cÃ³digos Python que demonstram e analisam diferentes complexidades algorÃ­tmicas, com exemplos prÃ¡ticos, testes e comparaÃ§Ãµes de desempenho.

## ğŸ“‹ DescriÃ§Ã£o

Projeto desenvolvido para demonstrar os princÃ­pios de complexidade em algoritmos, incluindo notaÃ§Ã£o Big O e anÃ¡lise de desempenho prÃ¡tico. Cada cÃ³digo foi testado e documentado para facilitar o entendimento dos conceitos.

## ğŸ¯ CÃ³digos Desenvolvidos

### 1. `busca_algoritmos.py` - Algoritmos de Busca

Demonstra e compara a complexidade de algoritmos de busca:

- **Busca Linear**: O(n)
- **Busca BinÃ¡ria**: O(log n)

**Funcionalidades:**
- ImplementaÃ§Ã£o com contagem de comparaÃ§Ãµes
- ComparaÃ§Ã£o de desempenho com diferentes tamanhos de dados
- DemonstraÃ§Ã£o de casos especÃ­ficos (inÃ­cio, meio, fim, elemento inexistente)
- AnÃ¡lise teÃ³rica vs prÃ¡tica

**Como executar:**
```bash
python busca_algoritmos.py
```

**Principais conclusÃµes:**
- Busca binÃ¡ria Ã© significativamente mais eficiente (atÃ© 3000x menos comparaÃ§Ãµes)
- Requer lista ordenada
- Para listas pequenas, busca linear pode ser adequada pela simplicidade

---

### 2. `ordenacao_algoritmos.py` - Algoritmos de OrdenaÃ§Ã£o

Demonstra e compara diferentes algoritmos de ordenaÃ§Ã£o:

- **Bubble Sort**: O(nÂ²)
- **Selection Sort**: O(nÂ²)
- **Merge Sort**: O(n log n)
- **Quick Sort**: O(n log n) mÃ©dio, O(nÂ²) pior caso

**Funcionalidades:**
- ImplementaÃ§Ã£o de 4 algoritmos clÃ¡ssicos
- ComparaÃ§Ã£o com listas aleatÃ³rias, ordenadas e reversas
- AnÃ¡lise de melhor, mÃ©dio e pior caso
- OtimizaÃ§Ãµes no Quick Sort (mediana de trÃªs + insertion sort para listas pequenas)

**Como executar:**
```bash
python ordenacao_algoritmos.py
```

**Principais conclusÃµes:**
- Algoritmos O(nÂ²) sÃ£o impraticÃ¡veis para listas grandes (>10.000 elementos)
- Merge Sort tem desempenho consistente O(n log n)
- Quick Sort Ã© mais rÃ¡pido na prÃ¡tica, mas pode degradar
- Para listas grandes, sempre use O(n log n)

---

### 3. `complexidade_exemplos.py` - Exemplos PrÃ¡ticos de Complexidades

Demonstra problemas prÃ¡ticos com diferentes complexidades:

- **O(1)**: Tempo Constante (acesso a array, busca em hash)
- **O(n)**: Tempo Linear (soma, busca de mÃ¡ximo)
- **O(nÂ²)**: Tempo QuadrÃ¡tico (encontrar duplicatas, multiplicaÃ§Ã£o de matrizes)
- **O(2^n)**: Tempo Exponencial (Fibonacci recursivo, subconjuntos)
- **O(n!)**: Tempo Fatorial (permutaÃ§Ãµes)

**Funcionalidades:**
- ImplementaÃ§Ãµes didÃ¡ticas de cada complexidade
- DemonstraÃ§Ãµes prÃ¡ticas com mediÃ§Ã£o de tempo
- ComparaÃ§Ã£o visual de crescimento das complexidades
- Tabela comparativa mostrando o crescimento de cada notaÃ§Ã£o

**Como executar:**
```bash
python complexidade_exemplos.py
```

**Principais conclusÃµes:**
- O(1), O(log n), O(n) e O(n log n) sÃ£o eficientes e escalÃ¡veis
- O(nÂ²) Ã© aceitÃ¡vel apenas para datasets pequenos
- O(2^n) e O(n!) sÃ£o impraticÃ¡veis para n > 30

---

## ğŸ“Š Resumo das Complexidades

### Eficientes (EscalÃ¡veis)
- **O(1)** - Constante: Melhor possÃ­vel, independente do tamanho
- **O(log n)** - LogarÃ­tmica: Muito eficiente (ex: busca binÃ¡ria)
- **O(n)** - Linear: Bom para a maioria dos casos
- **O(n log n)** - LinearÃ­tmica: Ã“timo para ordenaÃ§Ã£o

### AceitÃ¡veis (Uso Limitado)
- **O(nÂ²)** - QuadrÃ¡tica: Ok para datasets pequenos (<1000)
- **O(nÂ³)** - CÃºbica: Apenas para datasets muito pequenos

### Ineficientes (ImpraticÃ¡veis)
- **O(2^n)** - Exponencial: Apenas para n < 25
- **O(n!)** - Fatorial: Apenas para n < 12

---

## ğŸ”§ Requisitos

- Python 3.7 ou superior
- Bibliotecas padrÃ£o: `time`, `random`, `typing`, `math`

NÃ£o hÃ¡ dependÃªncias externas!

---

## ğŸš€ Como Usar

1. Clone o repositÃ³rio:
```bash
git clone <url-do-repositorio>
cd atv_cli
```

2. Execute qualquer um dos scripts:
```bash
python busca_algoritmos.py
python ordenacao_algoritmos.py
python complexidade_exemplos.py
```

3. Analise os resultados no console

---

## ğŸ“ˆ Resultados dos Testes

### Busca (100.000 elementos)
- **Busca Linear**: ~50.000 comparaÃ§Ãµes
- **Busca BinÃ¡ria**: ~17 comparaÃ§Ãµes
- **Ganho**: ~3000x mais eficiente

### OrdenaÃ§Ã£o (10.000 elementos)
- **Bubble Sort**: ~50.000.000 comparaÃ§Ãµes, 7.2s
- **Quick Sort**: ~156.000 comparaÃ§Ãµes, 0.03s
- **Ganho**: ~240x mais rÃ¡pido

### Complexidades
| n   | O(1) | O(log n) | O(n)  | O(nÂ²)    | O(2^n)      | O(n!)       |
|-----|------|----------|-------|----------|-------------|-------------|
| 10  | 1    | 3        | 10    | 100      | 1.024       | 3.628.800   |
| 20  | 1    | 4        | 20    | 400      | 1.048.576   | 2.43 Ã— 10Â¹â¸ |
| 30  | 1    | 5        | 30    | 900      | 1.073.741.824 | > 10Â³Â²    |

---

## ğŸ“š Conceitos Abordados

1. **NotaÃ§Ã£o Big O**: AnÃ¡lise assintÃ³tica de algoritmos
2. **Melhor, MÃ©dio e Pior Caso**: Diferentes cenÃ¡rios de execuÃ§Ã£o
3. **Complexidade de Tempo vs EspaÃ§o**: Trade-offs entre velocidade e memÃ³ria
4. **OtimizaÃ§Ãµes**: TÃ©cnicas para melhorar algoritmos (mediana de trÃªs, insertion sort hÃ­brido)
5. **AnÃ¡lise EmpÃ­rica**: MediÃ§Ã£o real de desempenho

---

## ğŸ“ Objetivos Educacionais

Este projeto demonstra:
- Como diferentes algoritmos escalam com o tamanho da entrada
- A importÃ¢ncia de escolher o algoritmo correto para cada problema
- Como medir e analisar o desempenho de algoritmos
- A diferenÃ§a entre anÃ¡lise teÃ³rica e desempenho prÃ¡tico

---

## ğŸ“ DocumentaÃ§Ã£o do CÃ³digo

Todos os cÃ³digos incluem:
- **Docstrings detalhadas** para cada funÃ§Ã£o
- **AnÃ¡lise de complexidade** (tempo e espaÃ§o)
- **ComentÃ¡rios explicativos** no cÃ³digo
- **Type hints** para clareza
- **Exemplos de uso** na seÃ§Ã£o `if __name__ == "__main__"`

---

## ğŸ¤ ContribuiÃ§Ãµes

Este Ã© um projeto educacional. SugestÃµes e melhorias sÃ£o bem-vindas!

---

## ğŸ‘¨â€ğŸ’» Autor

**Algoritmo Project**
Data: 2025-10-21

---

## ğŸ“– ReferÃªncias

- Introduction to Algorithms (CLRS)
- The Algorithm Design Manual (Skiena)
- Python Time Complexity: https://wiki.python.org/moin/TimeComplexity

---

## âš¡ Regra de Ouro

**Sempre prefira algoritmos com menor complexidade quando trabalhar com grandes volumes de dados!**

Para pequenos datasets, a simplicidade do cÃ³digo pode ser mais importante que a eficiÃªncia algorÃ­tmica.
